{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "//anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: \n",
    "1. pair predictions back to their original images.\n",
    "2. consider network to detect traps for cropping of traps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read 2048x2048 images, tile them in generator\n",
    "## Set up image generator\n",
    "\n",
    "We need to pull images from a given directory, and crop them to 256x256 sub-images.\n",
    "\n",
    "The `tileImage` function will do the cropping and arrange the sub-images into a tidy numpy array. `crop_generator` will accept a batch of images, and call `tileImage` on each image in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tileImage(img, subImageNumber):\n",
    "    divisor = int(np.sqrt(subImageNumber))\n",
    "    M = img.shape[0]//divisor\n",
    "    N = img.shape[0]//divisor\n",
    "    tiles = np.asarray([img[x:x+M,y:y+N] for x in range(0,img.shape[0],M) for y in range(0,img.shape[1],N)])\n",
    "    return(tiles)\n",
    "\n",
    "def crop_generator(batches, subImageNumber=64):\n",
    "    while True:\n",
    "        batch_imgs = next(batches)\n",
    "        x_subImageNumber = int(np.sqrt(subImageNumber))\n",
    "        crop_length = int(batch_imgs.shape[1]//x_subImageNumber)\n",
    "        batch_tiles = np.zeros((batch_imgs.shape[0]*subImageNumber, crop_length, crop_length, 1)) # array to store batch of tiled images\n",
    "        for i in range(batch_imgs.shape[0]):  # loop through all images in the batch\n",
    "            tile = tileImage(batch_imgs[i], subImageNumber=subImageNumber)\n",
    "            batch_tiles[i*tile.shape[0]:i*tile.shape[0]+tile.shape[0],...] = tile # toss the tiles image into its appropriate batch\n",
    "        yield (batch_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't augment the images, since this is a prediction task, and not a training task. No augmentation is the default behavior of the `ImageDataGenerator` class, so no need to define any arguments here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the image generator\n",
    "\n",
    "### NOTE:\n",
    "I had to modify the source code for tensorflow to get 16-bit images to read in correctly. My problem was that the pixel intensity values of all my 16-bit images, after reading in, were truncated to 255! \n",
    "\n",
    "Following the suggestion by jfx319 [here](https://github.com/keras-team/keras/issues/4486), I modified tensorflow's image.py code in `load_img` from:\n",
    "\n",
    "```python\n",
    "if grayscale:\n",
    "    if img.mode != 'L':\n",
    "        img = img.convert('L')\n",
    "```\n",
    "\n",
    "to now be:\n",
    "\n",
    "```python\n",
    "if grayscale:\n",
    "    img = img.convert('I')\n",
    "```\n",
    "\n",
    "That seems to be a fine fix.\n",
    "\n",
    "If you're not sure where to find tensorflow's image.py, I recommend running the following from your command line:\n",
    "\n",
    "```bash\n",
    "locate image.py | grep tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "batch_size=1 # Here, batch_size refers to the number of 2048x2048 images read in by the generator at once.\n",
    "             # Each image is cropped to 64 256x256 pixel sub-images.\n",
    "             # This means that a batch_size of 2 large images here translates to a batch_size of 2*64 sub-images when the generator is actually run\n",
    "subImageNumber = 64 # how many cropped sub-images to make from each large image\n",
    "\n",
    "#'/Volumes/GoogleDrive/My Drive/code_20180913/motherMachineSegger/full_image_data/test/images'\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory( # will take images from a directory\n",
    "    './shift35_imgs/test/images/', # the images are actually in 'full_image_data/test/images/cells' because flow_from_directory requires your images to be in sub-directories, assuming you have different classes of images in different sub-directories\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(2048,2048)) # defaults to (256,256), so make sure you define the full image size.\n",
    "\n",
    "test_crops = crop_generator(image_generator, subImageNumber=subImageNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for loss metrics\n",
    "\n",
    "This is ripped straight off of this [tutorial](https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb), in the **Defining custom metrics and loss functions** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the model that was saved when we ran train_Unet.ipynb\n",
    "\n",
    "Save time by checking if `model` is defined before deciding whether to read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    model\n",
    "except:\n",
    "    model = models.load_model('weights_20181009_e20.hdf5', custom_objects={'bce_dice_loss': bce_dice_loss,\n",
    "                                                           'dice_loss': dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConcatenator(imgStack, subImageNumber = 64):\n",
    "    \n",
    "    rowNumPerImage = int(np.sqrt(subImageNumber)) # here I'm assuming our large images are square, with equal number of crops in each dimension\n",
    "    imageNum = int(imgStack.shape[0]/subImageNumber) # total number of sub-images divided by the number of sub-images in each original large image\n",
    "    iterNum = int(imageNum*rowNumPerImage)\n",
    "    imageDims = int(np.sqrt(imgStack.shape[1]*imgStack.shape[2]*subImageNumber))\n",
    "    bigImg = np.zeros(shape=(imageNum, imageDims, imageDims), dtype='float32') # create array to store reconstructed images\n",
    "    rowDict = {}\n",
    "    \n",
    "    for i in range(iterNum):\n",
    "        baseNum = int(i*iterNum/imageNum)\n",
    "        # concatenate columns of 256x256 images to build each 256x2048 row\n",
    "        rowDict[i] = np.column_stack((imgStack[baseNum,:,:,0],imgStack[baseNum+1,:,:,0],imgStack[baseNum+2,:,:,0],imgStack[baseNum+3,:,:,0],imgStack[baseNum+4,:,:,0],imgStack[baseNum+5,:,:,0],imgStack[baseNum+6,:,:,0],imgStack[baseNum+7,:,:,0],))\n",
    "\n",
    "    for i in range(imageNum):\n",
    "        baseNum = int(i*rowNumPerImage)\n",
    "        # concatenate appropriate 256x2048 rows to build a 2048x2048 image and place it into bigImg\n",
    "        bigImg[i,:,:] = np.row_stack((rowDict[baseNum],rowDict[baseNum+1],rowDict[baseNum+2],rowDict[baseNum+3],rowDict[baseNum+4],rowDict[baseNum+5],rowDict[baseNum+6],rowDict[baseNum+7]))\n",
    "    \n",
    "    return(bigImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model on 256x256 cropped images\n",
    "\n",
    "Here we're cropping and feeding the images in one step by using our `test_crops` generator. The model runs on each 256x256 crop, and the resulting object is predictions for each crop from each large image in our test directory.\n",
    "\n",
    "`model.predict_generator` will handle taking batches of images from `test_crops` and stacking up the resulting predictions in the output. Note the `steps=stepNumber` argument here. It essentially defines how many distinct batches of images we are going to run the model on. Here I've written code to allow us to just run on all the images in the directory defined in the `test_crops` image generator. You can imagine a scenario, however, where we have thousands of images, and we won't be able to fit all their predictions into RAM at once. Maybe in that case we could set up a loop to run a few steps at a time, saving the resulting predictions to disk each time through the loop.\n",
    "\n",
    "After getting the model's predictions we reconstruct the full 2048x2048 predictions by concatenating the appropriate 256x256 crops using the `imageConcatenator` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageNumber = len(glob.glob('./shift35_imgs/test/images/cells/*.*'))\n",
    "stepNumber = int(np.ceil(imageNumber/batch_size))\n",
    "\n",
    "predictions = model.predict_generator(test_crops, steps=stepNumber)\n",
    "prediction = imageConcatenator(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(prediction.shape) # sanity check that the first dimention is imageNum long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13fd50790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction[prediction < 0.99] = 0 \n",
    "io.imshow(prediction[0, :, :])\n",
    "plt.savefig('./prediction20181009_1.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048, 2048)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
